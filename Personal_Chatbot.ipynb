{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NOSCnSMtxMu2"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate torch langchain langchain-huggingface -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "import torch\n",
        "\n"
      ],
      "metadata": {
        "id": "xUW8ZsUs--Hs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "fcee329ac46747018caac918645711c3",
            "ed9a507a00ae4aa481db833a0b63328f",
            "f2ab6fa82349492094199cebc6dbb5ab",
            "e48acdd55cd7472ca25c7afbfeec06a3",
            "0d298378e4b94877b4ac9277890660ad",
            "0bc1cbdb1d6a432195187b8b55294c5f",
            "8ee4524421624d4f9f77888da7a83cac",
            "0fc33bbbbd164ba181d4f120b8fa66a6",
            "4c93a3c22dda49ebaf0b1dc821a2db09",
            "4913171d780d4a148a02fe90e89e6b46",
            "f57b166793554305a61a3789f8ee8fde"
          ]
        },
        "id": "V1BhnA0T6OYp",
        "outputId": "e2cd6069-66c7-4ca9-b6bc-463f83c9770f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcee329ac46747018caac918645711c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"openchat/openchat-3.5-0106\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2se24vUK6j8v",
        "outputId": "e8c48dc6-b283-47bf-d4bc-0153eacafe16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    do_sample=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "\n",
        "template = \"\"\"You are a helpful AI assistant.\n",
        "Answer clearly and concisely.\n",
        "\n",
        "User: {question}\n",
        "Assistant:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n"
      ],
      "metadata": {
        "id": "ukuknI0w90Lz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Chat is ready! Type 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    question = input(\" You: \")\n",
        "    if question.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Exiting chat...\")\n",
        "        break\n",
        "\n",
        "    response = chain.run(question)\n",
        "    print(f\"OpenChat: {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTTb8C2R90Nv",
        "outputId": "58ba8ad1-38cc-4b5c-cd99-5ba0efc25f0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Chat is ready! Type 'exit' to quit.\n",
            "\n",
            " You: What is CNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenChat: You are a helpful AI assistant.\n",
            "Answer clearly and concisely.\n",
            "\n",
            "User: What is CNN\n",
            "Assistant: CNN (Cable News Network) is an American news-based pay television channel that was founded in 1980 by American media proprietor Ted Turner. It is a division of WarnerMedia and is one of the most widely viewed cable news networks in the United States. CNN provides news coverage and analysis across various formats, including television, digital platforms, and podcasts. The network is known for its extensive coverage of major news events and political stories, as well as for its on-the-ground reporting from around the world. CNN's slogan is \"The Most Trusted Name in News.\"\n",
            "\n",
            "Keep in mind that CNN has faced criticism and controversies over the years regarding its journalistic practices and coverage. However, it remains a significant player in the global news landscape.\n",
            "\n",
            " You: What is CNN in deep learning\n",
            "OpenChat: You are a helpful AI assistant.\n",
            "Answer clearly and concisely.\n",
            "\n",
            "User: What is CNN in deep learning\n",
            "Assistant: In deep learning, CNN stands for Convolutional Neural Network. It is a type of artificial neural network specifically designed to process and analyze visual imagery. CNNs are inspired by the structure and function of the human visual cortex and use convolutional layers to scan and extract features from the input images. These layers are followed by pooling layers to reduce the spatial dimensions and fully connected layers to classify the extracted features. CNNs have achieved state-of-the-art performance in various computer vision tasks, such as image recognition, object detection, and image segmentation.\n",
            "\n",
            " You: exit\n",
            "Exiting chat...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    
  },
  "nbformat": 4,
  "nbformat_minor": 0
}